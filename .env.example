QDRANT_URL=http://qdrant:6333

EMBEDDING_MODEL_NAME=BAAI/bge-m3
RERANKER_MODEL_NAME=BAAI/bge-reranker-v2-m3
RERANKER_ENABLED=false

# Кеш моделей HuggingFace / sentence-transformers
HF_HOME=/hf-cache

# Настройки поиска
SEARCH_COLLECTION=support_knowledge
SEARCH_TOP_K=5
SEARCH_LIMIT=8
SEARCH_SCORE_THRESHOLD=0.5

# Настройки чанкинга (работаем по символам)
CHUNK_MAX_LENGTH=512
CHUNK_OVERLAP=100

# Настройки чат-агента
REDIS_URL=redis://redis:6379/0
RETRIEVAL_URL=http://ingest-and-retrieval:8000
SCENARIO_STORAGE_PATH=data
AGENT_PIPELINE_VERSION=1.0

# Настройки LLM (OpenAI-совместимый API, например OpenRouter).
# Имена переменных OPENAI_* выбраны только для совместимости с SDK.
OPENAI_API_KEY=sk-or-v1-REPLACE_ME
OPENAI_BASE_URL=https://openrouter.ai/api/v1
LLM_MODEL=tngtech/deepseek-r1t2-chimera:free

# Модель для SGR-конвертера (/sgr/convert). Если не задана — используется LLM_MODEL.
SGR_MODEL=nex-agi/deepseek-v3.1-nex-n1:free
# Логировать промпты/ответы SGR-конвертера в container logs (1/0).
SGR_LOG_PROMPTS=1
# Таймаут каждого LLM-шага SGR-конвертера (секунды).
SGR_TIMEOUT_S=120
# Куда сохранять трассы LLM-шагов (request/response) внутри контейнера.
# Если используете docker-compose volume, можно указать /sgr_traces.
SGR_TRACE_DIR=/sgr_traces

# Модели по ролям (если не заданы — используются значения LLM_MODEL)
CONDITION_MODEL=nex-agi/deepseek-v3.1-nex-n1:free
JUDGE_MODEL=nex-agi/deepseek-v3.1-nex-n1:free
REVISE_MODEL=nex-agi/deepseek-v3.1-nex-n1:free
SUMMARY_MODEL=nex-agi/deepseek-v3.1-nex-n1:free
